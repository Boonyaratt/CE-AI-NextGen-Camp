{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#!! หมายเหตุ: ผมได้อธิบาย แสดง pytorch code class ของโครงสร้าง ในรูปแบบ comment หลังบรรทัด หากเข้าใจโจทย์ผิด ขออภัยมา ณ ที่นี้\n",
    "\n",
    "# สร้างคลาส CustomCNN ที่สืบทอดจาก nn.Module\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, input_size=(3, 128, 128)):  # input_size คือ (channels, height, width)\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        # ชุดแรกของ Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_size[0], out_channels=16, kernel_size=3, stride=1, padding=1)  # Conv2D: 3x128x128 → 16x128x128\n",
    "        self.relu1 = nn.ReLU()  # Activation ReLU\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)  # Conv2D: 16x128x128 → 16x128x128\n",
    "        self.relu2 = nn.ReLU()  # Activation ReLU\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool: 16x128x128 → 16x64x64\n",
    "\n",
    "        # ชุดที่สองของ Convolutional Layers\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=5, stride=1, padding=0)  # Conv2D: 16x64x64 → 64x60x60\n",
    "        self.relu3 = nn.ReLU()  # Activation ReLU\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=0)  # Conv2D: 64x60x60 → 128x56x56\n",
    "        self.relu4 = nn.ReLU()  # Activation ReLU\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool: 128x56x56 → 128x28x28\n",
    "\n",
    "        self.flatten = nn.Flatten()  # แปลง tensor เป็น vector สำหรับ Fully Connected\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(self.get_input_size_fc1(input_size), 200)  # Linear: 128x28x28 (100352) -> 200\n",
    "        self.relu5 = nn.ReLU()  # Activation ReLU\n",
    "        self.fc2 = nn.Linear(200, 64)  # Linear: 200 -> 64\n",
    "        self.relu6 = nn.ReLU()  # Activation ReLU\n",
    "        self.fc3 = nn.Linear(64, 10)  # Linear: 64 -> 10 (จำนวน class ที่ต้องการ)\n",
    "    \n",
    "    def get_input_size_fc1(self, input_shape):  # ฟังก์ชันสำหรับคำนวณขนาด input ให้ fc1\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, *input_shape)  # สร้าง input จำลอง\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.pool1(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu3(x)\n",
    "            x = self.conv4(x)\n",
    "            x = self.relu4(x)\n",
    "            x = self.pool2(x)\n",
    "\n",
    "            x = self.flatten(x)\n",
    "            return x.size(1)  # ส่งขนาด vector สำหรับ Fully Connected Layer\n",
    "\n",
    "    def forward(self, x):  # ฟังก์ชันที่กำหนดการไหลของข้อมูล\n",
    "        x = self.conv1(x)  # Conv Layer 1\n",
    "        x = self.relu1(x)  # ReLU 1\n",
    "        x = self.conv2(x)  # Conv Layer 2\n",
    "        x = self.relu2(x)  # ReLU 2\n",
    "        x = self.pool1(x)  # MaxPool 1\n",
    "\n",
    "        x = self.conv3(x)  # Conv Layer 3\n",
    "        x = self.relu3(x)  # ReLU 3\n",
    "        x = self.conv4(x)  # Conv Layer 4\n",
    "        x = self.relu4(x)  # ReLU 4\n",
    "        x = self.pool2(x)  # MaxPool 2\n",
    "\n",
    "        x = self.flatten(x)  # Flatten เพื่อเข้า Fully Connected\n",
    "\n",
    "        x = self.fc1(x)  # Fully Connected 1\n",
    "        x = self.relu5(x)  # ReLU 5\n",
    "        x = self.fc2(x)  # Fully Connected 2\n",
    "        x = self.relu6(x)  # ReLU 6\n",
    "        x = self.fc3(x)  # Fully Connected 3 (Output)\n",
    "\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
